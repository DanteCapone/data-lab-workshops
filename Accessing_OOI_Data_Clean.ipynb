{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Accessing OOI Data.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "LiPthtG3isLc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Accessing OOI Data - An Ocean Data Labs Introduction\n",
        "*Written by Sage Lichtenwalner, Rutgers University, March 6, 2019*\n",
        "\n",
        "*The example was developed for the [March 2019 OOI Ocean Data Labs Workshop](https://datalab.marine.rutgers.edu/workshops/data-lab-workshop-march-2019/)*\n"
      ]
    },
    {
      "metadata": {
        "id": "yuiA4yCOva4C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "In this Python notebook, we will demonstrate how to access and work with data from the Ocean Observatories Initiative (OOI). This example was designed to run on Google's Colaboratory platform, though it should also work on any Jupyter notebook platform, assuming the required libraries are installed.  In this notebook, we will demonstrate the following steps:\n",
        "1.  Discovering OOI Data to Use\n",
        "2.  Requesting OOI Data\n",
        "3.  Loading Data\n",
        "4. Quick Plots\n",
        "5. Basic Statistics and Analysis\n",
        "6. Exporting Data for Use in Other Software"
      ]
    },
    {
      "metadata": {
        "id": "NOBDkOPxiKGe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Discovering OOI Data to Use\n",
        "\n",
        "There are a number of ways to discover data from the OOI. Obviously, if you've seen data used in a paper, or we're told about an interesting dataset from a colleague, those are good places to start.  You can also browse the instrument lists available on: \n",
        "\n",
        "* the main [OOI Website](https://oceanobservatories.org/research-arrays/), \n",
        "* the [OOI Data Portal](https://ooinet.oceanobservatories.org), \n",
        "* or the [OOI Data Review Portal](https://ooi-visualocean.whoi.edu).\n",
        "\n",
        "The latter two sites provide coverage information so you can see what data is available for specific time periods.\n",
        "\n",
        "Regardless of the approach, ultimate you will need to know the **Reference Designator** of the instrument you wish to access.  This 27-character code unique defines the instrument in the system, and with it, you can access information and data from the Data Portal for that instrument.\n",
        "![OOI Irminger Sea Array](https://oceanobservatories.org/wp-content/uploads/2015/09/CEV-OOI-Global-Irminger-Sea.jpg =450x)\n",
        "\n",
        "For this example, we will use the **30m Dissolved Oxygen** sensor on the **[Global Irminger Sea Flanking Mooring A](https://oceanobservatories.org/site/gi03flma/)**, aka **GI03FLMA-RIS01-03-DOSTAD000**.  You can find out more information about this instrument on the above sites, or on the new [Rutgers OOI Data Review portal](https://datareview.marine.rutgers.edu/instruments/view/GI03FLMA-RIS01-03-DOSTAD000)."
      ]
    },
    {
      "metadata": {
        "id": "E3IDcQleiKKG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Requesting OOI Data\n",
        "\n",
        "Most of the data available from the OOI can be downloaded from the [OOI Data Portal](https://ooinet.oceanobservatories.org), also called OOI Net.  Cruise data or data from speciality instruments, including cameras, sonars, seismic sensors and hydrophones, require a different approach.\n",
        "\n",
        "The main advantage of OOI Net is that it provides a standardized way to request data from the OOI and all of the data returned is in a simlar format, generally NetCDF files, but for smaller time periods, you can also request CSV data files.\n",
        "\n",
        "**There are two ways to request data from the OOI data portal:**\n",
        "\n",
        "1. You can use the Data Portal's API to request data programmatically.  This is particularly useful when you want to request data from a number of instruments, or you want to write a script to access data on a regular basis.  If you would like to use this approach, I recommend checking out the [Quick Start or Example 1 notebooks](https://github.com/ooi-data-review/2018-data-workshops/tree/master/chemistry/examples) from our previous Data Workshops. \n",
        "\n",
        "2. You can also request data manually using the Data Portal.  Simply log in, navigate to the instrument you are interested in, and then make a download request for the instrument and time frame you're interested in.  \n",
        "\n",
        "Regardless of the approach you take, you will receive an email the URL links to the directory that contains the data you requested.\n",
        "\n",
        "**Important Note:** The OOI Data Portal processed data \"on-demand.\" This means, that you will get a unique directory for each request you make.  Thus, there's no need to make the same request multiple times.  But also, keep in mind that your personalized directory may only exist for a few months."
      ]
    },
    {
      "metadata": {
        "id": "IxLQGLeSVPhz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Let's request some DO Data\n",
        "For the purposes of this example, we will make our request manually using the Data Portal. \n",
        "\n",
        "You can either search for the instrument, or navigate to it.  Here's the [direct link](https://ooinet.oceanobservatories.org/data_access/?search=GI03FLMA-RIS01-03-DOSTAD000) to the data stream catalog for the DO instrument we're interested in.  From there, select the \"recovered_host\" stream, and then go ahead and make a download request for the full range of data available.  \n",
        "\n",
        "After a few minutes, you will receive an email with two different URLs where the resulting data files can be found, a THREDDS version and a regular web site link.  Whenever you make a download request, whether you use the data portal or the API, you should also receive an email with the links in case you forgot to save them when you made the request.\n",
        "\n",
        "For this example, we will want the first URL to the **THREDDS catalog version** of our dataset.  For reference, here's the [link I received](https://opendap.oceanobservatories.org/thredds/catalog/ooi/sage-marine-rutgers/20190307T155319-GI03FLMA-RIS01-03-DOSTAD000-recovered_host-dosta_abcdjm_sio_instrument_recovered/catalog.html) that we will use for this example."
      ]
    },
    {
      "metadata": {
        "id": "TEYHU1qb3adF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### NASA Panoply\n",
        "\n",
        "Once the dataset has finished processing, you can download the resulting NetCDF files and start playing with the data locally on your machine using Python or Matlab. You can also use [NASA's Panoply](https://www.giss.nasa.gov/tools/panoply/) software to open the NetCDF files. This is a great tool to peruse the metadata and make some quick plots."
      ]
    },
    {
      "metadata": {
        "id": "xCOIdXnRiKNo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Loading Data\n",
        "\n",
        "Okay, so let's start coding... \n",
        "\n",
        "The first thing we need to do is load  [xarray](http://xarray.pydata.org/en/stable/) which will help us load and work with the NetCDF files.  We also need to install the netcdf4 library."
      ]
    },
    {
      "metadata": {
        "id": "eHk8O3nWiDi4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import xarray as xr\n",
        "!pip install netcdf4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YdSTlBG44TvQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Loading a single NetCDF data file\n",
        "Above, we requested all of the data available in the system for the DO instrument. This resulted in quite a few of files in the output directory.\n",
        "* By default, the system will break up data files into individual deployments. \n",
        "* It will also break up the deployments if the files are larger than ~500MB.\n",
        "* For some instruments, they system will also include other dependent instruments in the output.  In this case, a CTD was needed to calculate some of the higher-level DO variables.\n",
        "\n",
        "If we only want to load a **single NetCDF data file** (perhaps we only want one deployment or we only have one file), we could easily load it by specifying the direct link to the .nc file.\n",
        "\n",
        "To choose a single deployment file from the THREDDS catalog...\n",
        "* click on the deployment/file you wish to use\n",
        "* then click on the \"OPENDAP\" link\n",
        "* and then copy the \"Data URL\" from the text box.\n",
        "\n",
        "We'll add that link here as a variable."
      ]
    },
    {
      "metadata": {
        "id": "1_UgrbqO7W-f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "single_file = 'https://opendap.oceanobservatories.org/thredds/dodsC/ooi/sage-marine-rutgers/20190307T155319-GI03FLMA-RIS01-03-DOSTAD000-recovered_host-dosta_abcdjm_sio_instrument_recovered/deployment0001_GI03FLMA-RIS01-03-DOSTAD000-recovered_host-dosta_abcdjm_sio_instrument_recovered_20140912T201501-20150818T103001.nc'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g2L-dYR57jpX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can now easily load this file using xarray."
      ]
    },
    {
      "metadata": {
        "id": "POgkQjkF4Rai",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the data files\n",
        "ds = xr.open_dataset(single_file)\n",
        "\n",
        "# By default, OOI datasets use the 'obs' variable as the index, but time is more convenient\n",
        "ds = ds.swap_dims({'obs': 'time'})\n",
        "\n",
        "ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mqXOTFdpv1OU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Investigating Metadata (variable and attribute selection)\n",
        "Thanks to xarray, we can easily access the global metadata as well as the metadata for individual variables. You can refer to the full list of variables an attributes outputted above.\n",
        "Here are a few examples."
      ]
    },
    {
      "metadata": {
        "id": "wMtMAQBgvs_m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ds.source"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vj2Rsqg-v5HL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'%s-%s-%s' % (ds.subsite,ds.node,ds.sensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "owaGEqB4v6f9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ds['dissolved_oxygen']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GndNVcdzv8cE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "textwrap.wrap(ds['dissolved_oxygen'].comment)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hC2SHIeBv-Kp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ds['dissolved_oxygen'].dims"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DygeViXzv_pQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ds['dissolved_oxygen'].coords['int_ctd_pressure'].units"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oJvy_hBfiKR5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. Quick Plots\n",
        "\n",
        "And now we can really start having some fun... To start, we can use the built in matplotlib plotting routines in xarray to make a plot."
      ]
    },
    {
      "metadata": {
        "id": "drlAkJB37-eQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ds['ctdmo_seawater_temperature'].plot();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "buB7ylyD8OjI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can also quickly make a histogram."
      ]
    },
    {
      "metadata": {
        "id": "Uzatr3dV4Rc-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ds['ctdmo_seawater_temperature'].plot.hist(bins=100);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KAmy5GC_8Spk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And we can plot a bunch of variables at once.  \n",
        "\n",
        "To do this, we also need to load the matplotlib library directly (even though it's already included in xarray) so we can create subplots."
      ]
    },
    {
      "metadata": {
        "id": "cO28cq658W66",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NfD0uf5t4Rfc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig, (ax1,ax2,ax3) = plt.subplots(3,1, sharex=True, figsize=(14,9))\n",
        "ds['ctdmo_seawater_temperature'].plot(ax=ax1)\n",
        "ds['practical_salinity'].plot(ax=ax2)\n",
        "ds['dissolved_oxygen'].plot(ax=ax3);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S2IG6qjgA1_3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's try it again using dots instead of lines.  We'll also add pressure."
      ]
    },
    {
      "metadata": {
        "id": "OY9V7sxKA1t7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig, (ax1,ax2,ax3,ax4) = plt.subplots(4,1, sharex=True, figsize=(14,9))\n",
        "ds['ctdmo_seawater_temperature'].plot(ax=ax1,linestyle='None',marker='.',markersize=1)\n",
        "ds['practical_salinity'].plot(ax=ax2,linestyle='None',marker='.',markersize=1)\n",
        "ds['int_ctd_pressure'].plot(ax=ax3,linestyle='None',marker='.',markersize=1);\n",
        "ds['dissolved_oxygen'].plot(ax=ax4,linestyle='None',marker='.',markersize=1);\n",
        "\n",
        "# Let's change the salinity y-limits to account for outliners\n",
        "ax2.set_ylim(34.6,35.2);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ByMH6igaGKbk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note, that the average pressure is just shy of 20m, but this instrument was supposed to be at 30m.  So what's up?  It turns out, for this deployment, the mooring was deployed 10-15m shallower that planned.  In this case, 30m was the *design depth,* but it's always a good idea to check the actual pressure measurements when possible."
      ]
    },
    {
      "metadata": {
        "id": "qR91ZtjRFYkN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### And now let's make a TS plot"
      ]
    },
    {
      "metadata": {
        "id": "ghIWj_oqFbiP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.scatter(ds.practical_salinity,ds.ctdmo_seawater_temperature,s=5)\n",
        "plt.xlabel('Salinity')\n",
        "plt.ylabel('Temperature')\n",
        "\n",
        "# Add a quick title from the metadata\n",
        "plt.title(ds.source);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w4o78p1KoqoT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Subsetting the dataset\n",
        "So from the figure above, we noticed some spurious data.  My guess is that the line of data heading off to the left is from when the instrument was recovered.  Let's subset the data so we can remove that line, and additionally focus in on a narrower time period."
      ]
    },
    {
      "metadata": {
        "id": "xfOfZTS0pNsD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ds2 = ds.loc[dict(time=slice('2014-10-01', '2014-10-31'))]\n",
        "\n",
        "ds2.ctdmo_seawater_temperature.plot();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xAVsBDkGqJ8m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.scatter(ds2.practical_salinity,ds2.ctdmo_seawater_temperature,s=5,c=ds2.time, cmap='viridis')\n",
        "plt.xlabel('Salinity')\n",
        "plt.ylabel('Temperature')\n",
        "\n",
        "# Quick title from the file\n",
        "plt.title(ds.source); \n",
        "\n",
        "# Add a colorbar\n",
        "cbar = plt.colorbar(label='Time');\n",
        "\n",
        "# Fix the colorbar ticks\n",
        "import pandas as pd # We need pandas for this\n",
        "cbar.ax.set_yticklabels(pd.to_datetime(cbar.get_ticks()).strftime(date_format='%Y-%m-%d'));"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gmHmD08ViKXA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 5. Basic Statistics and Analysis\n",
        "\n",
        "For many of these snippets, we will need to import the pandas library, if we haven't already."
      ]
    },
    {
      "metadata": {
        "id": "C34m4XCzvU8q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6YnpFq8vBuYA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Identifying the Sampling Frequency\n",
        "\n",
        "We can use the following snippet of code to find out the typical sampling frequency of the dataset. Note, this may take a while to calculate."
      ]
    },
    {
      "metadata": {
        "id": "pYKGe4vpBdgV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = ds.to_dataframe()\n",
        "res = (pd.Series(df.index[1:]) - pd.Series(df.index[:-1])).value_counts()\n",
        "res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AqPDpwkNB0Sp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Some quick statistics\n",
        "\n",
        "We can convert the xarray Dataset into a pandas Dataframe to do some quick statistical calculations."
      ]
    },
    {
      "metadata": {
        "id": "t39sFd1QB2Rv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = ds[['ctdmo_seawater_temperature','practical_salinity','dissolved_oxygen']].to_dataframe()\n",
        "df = df.drop(columns=['obs','lon','lat']) #Drop unnecessary columns\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Rxp1cHmCDqg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Prepare to be blown away...\n",
        "df.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o-WO4xb-Cb2G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Downsampling\n",
        "We can also easily calculate hourly, daily and monthly averages. See the [pandas.resample](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.resample.html) doc for more, as well as this list of [offset options](http://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases).\n",
        "\n",
        "That said, if you want to use centered averaging, moving averages, or other more complicated averaging or filtering routines using irregular intervals, you might have to roll-your-own code."
      ]
    },
    {
      "metadata": {
        "id": "nyI8lplKCgan",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(16, 6)\n",
        "df['ctdmo_seawater_temperature'].plot(ax=ax,label='Raw',linestyle='None',marker='.',markersize=2)\n",
        "df['ctdmo_seawater_temperature'].resample('D').mean().plot(ax=ax,label='Daily')\n",
        "df['ctdmo_seawater_temperature'].resample('5D').mean().plot(ax=ax,label='5 Day')\n",
        "df['ctdmo_seawater_temperature'].resample('MS').mean().plot(ax=ax,label='Monthly',marker='d') #MS=Month Start\n",
        "plt.legend();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XsQGyFhfiKbB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 6. Exporting Data\n",
        "\n",
        "Above we converted our xarray Dataset into a pandas Dataframe. Xarray is great for loading and exporting netcdf data, while Pandas is great for doing the same with CSV.\n",
        "\n",
        "Now that we have our data in a pandas Data frame, we can easily use the .to_csv() method to create a CSV file."
      ]
    },
    {
      "metadata": {
        "id": "eKtxMXBVD2un",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a CSV file with the raw dataset\n",
        "df.to_csv('output.csv') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "65-sXxGvEZSg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Export the daily averaged data\n",
        "df.resample('D').mean().to_csv('output_daily.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "57Zbz1SlD3wu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# If we have a large file, you can compress it using:\n",
        "# !gzip output.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KayL0MhiD8Rh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ls -l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ubuRvxVbB2P0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Appendix 1: Equilibrium DO\n",
        "In the Jigsaw activity, we actually compared the measured DO with the equilibrium DO, which is the amount of DO that would be in seawater if it was in equilibrium with the atmosphere.  Any deviation from that is likely due to biological or chemical processes, including respiration or photosynthesis.\n",
        "\n",
        "We can easily calculate this value using the [gsw_O2sol](http://www.teos-10.org/pubs/gsw/html/gsw_O2sol.html) function in the Gibbs Seawater Toolbox."
      ]
    },
    {
      "metadata": {
        "id": "1OtdYQFxDsix",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install gsw\n",
        "import gsw"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LaQj2YlcI8BU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "eo = gsw.O2sol_SP_pt(ds.practical_salinity,ds.ctdmo_seawater_temperature)\n",
        "ds['dissolved_oxygen'].plot(label='Measured DO',marker='.',markersize=3,linestyle='')\n",
        "plt.plot(ds.time,eo,'k.',label='Equilibrium DO',markersize=3)\n",
        "plt.legend();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UMyU-uPH3SRK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Appendix 2: There's more to the DO saga\n",
        "In the Jigsaw activity, we used the data shown in [The North Atlantic Biological Pump: Insights from the OOI Irminger Sea Array](https://tos.org/oceanography/article/the-north-atlantic-biological-pump-insights-from-the-ocean-observatories-in) by Palevsky and Nicholson.  Hillary was kind enough to share her dataset so we could make the activity.  But if you read the paper (and its supplement), you'll see that the authors actually did a lot of work to clean up the dataset, including:\n",
        "* Omitting daylight hours when phytoplankton may be over-saturating the water column\n",
        "* Omitting times when the mixed-layer was above the instrument\n",
        "* Calibrating the initial data with the ship board samples\n",
        "* Correcting drift over time, by comparing the surface instruments with profiling ones, using the assumption that DO at 2000m should remain constant over time.\n",
        "* Removing spikes and other outliers, and more.\n",
        "\n",
        "It's important to note, that while the OOI makes a lot of data available, it's essentially a research dataset, and an early one at that.  Thus, the data may not yet be research-ready.  Because the OOI is still young, some of the more complicated datasets (like DO) will require additional efforts by the community to resolve issues in how the measurements are made and calibrated.\n",
        "\n",
        "As an example, let's try to fix the initial offset in the data, by aligning it to the ship-based DO Winkler titration."
      ]
    },
    {
      "metadata": {
        "id": "g9UWgPuAHp2o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To do this, we will calculate a correction factor, based on the average temperature, salinity, density and measured DO for the date of the ship measurement.  We can find the appropriate depth to pressure value from [this calculator](http://www.calctool.org/CALC/other/games/depth_press)."
      ]
    },
    {
      "metadata": {
        "id": "Adr8olJiCTbk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Correction factor\n",
        "t = ds.ctdmo_seawater_temperature.sel(time=slice('2014-10-17','2014-10-17')).mean()\n",
        "s = ds.practical_salinity.sel(time=slice('2014-10-17','2014-10-17')).mean()\n",
        "d = gsw.rho(s,t,26.2154) # Pressure at 16m depth = 26.2154 dbar\n",
        "\n",
        "# Now we convert the measured Oxygen\n",
        "bottle_val = 6.653 # in mL/L from GI Deployment 1 Cruise Cast #9\n",
        "# Converstion 1 mL/L = 103/22.391 = 44.661 μmol/L\n",
        "cast_do = bottle_val*44.661*1000/d # in μmol/kg\n",
        "\n",
        "measured_do = ds.dissolved_oxygen.sel(time=slice('2014-10-17','2014-10-17')).mean()\n",
        "measured_do.load()\n",
        "\n",
        "do_correction = measured_do - cast_do\n",
        "do_correction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_8I3HIyREE_I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Add corrected DO\n",
        "ds['dissolved_oxygen_corrected'] = ds.dissolved_oxygen - (do_correction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0NjObVnR4eFA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Now let's plot the data\n",
        "\n",
        "# ds.dissolved_oxygen.sel(time=slice('2014-09-17')).plot(label='Original');\n",
        "# ds.dissolved_oxygen_corrected.sel(time=slice('2014-09-17')).plot(label='Corrected');\n",
        "\n",
        "ds.dissolved_oxygen.plot(label='Original',marker='.',markersize=3,linestyle='');\n",
        "ds.dissolved_oxygen_corrected.plot(label='Corrected',marker='.',markersize=3,linestyle='');\n",
        "\n",
        "# And we'll include the Equilibrim Line as well\n",
        "plt.plot(ds.time,eo,'k.',label='Equilibrium DO',markersize=2)\n",
        "\n",
        "plt.legend();\n",
        "\n",
        "plt.title(ds.source);\n",
        "plt.ylim([240,400])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ODMRba07zI4F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Appendix 3: Adding Contours to a TS Diagram\n",
        "While we created a TS diagram above, let's now add the density contours, as demonstrated by the [Ocean Python T-S Diagram](https://oceanpython.org/2013/02/17/t-s-diagram/) example, though we will use meshgrid instead.\n",
        "\n",
        "To calculate density, we will need the wonderful [seawater](https://pythonhosted.org/seawater/index.html) library."
      ]
    },
    {
      "metadata": {
        "id": "GL4CPys2z4ah",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install seawater\n",
        "import seawater\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ChdVCeWVz8NC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TS Diagram with density contours\n",
        "x = np.arange(34.8, 34.94, .01)\n",
        "y = np.arange(5, 7.75, .05)\n",
        "X, Y = np.meshgrid(x, y)\n",
        "\n",
        "Z = seawater.eos80.dens0(X,Y) - 1000 # Substract 1000 to convert to sigma-t\n",
        "\n",
        "# Plot the contour lines\n",
        "CS = plt.contour(X, Y, Z, colors='grey', linestyles='dashed')\n",
        "plt.clabel(CS, inline=1, fontsize=10, fmt='%0.2f')\n",
        "\n",
        "# Plot the data\n",
        "plt.scatter(ds2.practical_salinity,ds2.ctdmo_seawater_temperature,s=5,c=ds2.time, cmap='viridis')\n",
        "plt.xlabel('Salinity')\n",
        "plt.ylabel('Temperature °C')\n",
        "plt.title('Data from %s' % ds2.subsite);\n",
        "\n",
        "# Add a colorbar\n",
        "cbar = plt.colorbar(label='Time');\n",
        "\n",
        "# Fix the colorbar ticks\n",
        "import pandas as pd # We need pandas for this\n",
        "cbar.ax.set_yticklabels(pd.to_datetime(cbar.get_ticks()).strftime(date_format='%Y-%m-%d'));"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0aNFsu9zHqEL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Appendix 4: Seaborn Pair Plot\n",
        "The seaborn library provides a number of cool features.  One is the ability to quickly make a pair plot or scatterplot matrix."
      ]
    },
    {
      "metadata": {
        "id": "8FE-YiZjHqWp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.pairplot(df[['ctdmo_seawater_temperature','practical_salinity','dissolved_oxygen']]);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0-HIiAGi868T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Appendix 5: Loading and concatenating multiple files\n",
        "\n",
        "We can also concatenate multiple .nc files using xarray.  For this, we will need a few more libraries."
      ]
    },
    {
      "metadata": {
        "id": "7uUmNQlV9C9d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "import re\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yQQ_shmE9GWL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First we need to build up a list of all of the files we wish to include. To start, let's specify the THREDDS url which contains all of our data files.  This is the link you received in your email."
      ]
    },
    {
      "metadata": {
        "id": "jOb-D8AN9Lya",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "url = 'https://opendap.oceanobservatories.org/thredds/catalog/ooi/sage-marine-rutgers/20190307T155319-GI03FLMA-RIS01-03-DOSTAD000-recovered_host-dosta_abcdjm_sio_instrument_recovered/catalog.html'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KJshkPeA9Xw1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we can use the following code to automatically find all of the available .nc files in the directory."
      ]
    },
    {
      "metadata": {
        "id": "rDfawKMb9Z7g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tds_url = 'https://opendap.oceanobservatories.org/thredds/dodsC'\n",
        "datasets = requests.get(url).text\n",
        "urls = re.findall(r'href=[\\'\"]?([^\\'\" >]+)', datasets)\n",
        "x = re.findall(r'(ooi/.*?.nc)', datasets)\n",
        "for i in x:\n",
        "    if i.endswith('.nc') == False:\n",
        "        x.remove(i)\n",
        "for i in x:\n",
        "    try:\n",
        "        float(i[-4])\n",
        "    except:\n",
        "        x.remove(i)\n",
        "datasets = [os.path.join(tds_url, i) for i in x]\n",
        "datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xbSU0dKh9fLI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note, when requesting data from some instruments, you will actually get data files from multiple instruments, when they are needed to calculate derived parameters. When this happens, we need to modify the code above or tweak the resultant list to make sure you only include .nc files from the instrument you are interested in.\n",
        "\n",
        "This snippet removes the CTD files from the list, so all we have are the DO files."
      ]
    },
    {
      "metadata": {
        "id": "dvRq-ae19mQ9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "selected_datasets = []\n",
        "for d in datasets:\n",
        "  if 'CTD' in d:\n",
        "    pass\n",
        "  else:\n",
        "    selected_datasets.append(d)\n",
        "selected_datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TQ2ZEI319mg9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can use open_mfdataset() to load all files into a single xarray dataset.  This may take a minute.\n"
      ]
    },
    {
      "metadata": {
        "id": "b-EaULvI9n8B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ds = xr.open_mfdataset(selected_datasets)\n",
        "ds = ds.swap_dims({'obs': 'time'}) # Swap the primary dimension\n",
        "ds = ds.chunk({'time': 100}) # Used for optimization\n",
        "ds = ds.sortby('time') # Data from different deployments can overlap so we want to sort all data by time stamp."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hk4yeYKs_rmP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# How big is this Dataset\n",
        "ds.dissolved_oxygen.size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4wlfyfK6-tEI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Figure time\n",
        "fig, (ax1,ax2,ax3) = plt.subplots(3,1, sharex=True, figsize=(14,9))\n",
        "ds['ctdmo_seawater_temperature'].plot(ax=ax1,marker='.',linestyle='')\n",
        "ds['practical_salinity'].plot(ax=ax2,marker='.',linestyle='')\n",
        "ds['dissolved_oxygen'].plot(ax=ax3,marker='.',linestyle='');\n",
        "\n",
        "# ax3.set_ylim(200,600);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uUDfeJKUx_V6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## And even more fun\n",
        "\n",
        "To continue the fun of playing with OOI data in python, I recommend checking out these other examples:\n",
        "\n",
        "* [Plotting DO Profiles](https://github.com/ooi-data-review/2018-data-workshops/blob/master/chemistry/examples/Example_3_DO_Profiles.ipynb) - Includes more examples on subsetting data and changing colormaps.\n",
        "* Aggregation and Resampling - Useful when you have a large dataset\n",
        "* [Multi-instrument Quick Plots](https://github.com/ooi-data-review/2018-data-workshops/blob/master/chemistry/examples/extras1/Multi_instrument_Quick_Plots.ipynb)\n",
        "* [Plotting Profiler Data in Real-Time](https://github.com/ooi-data-review/2018-data-workshops/blob/master/chemistry/examples/extras1/Realtime_Plotting.ipynb)\n",
        "* [Working with ADCP Data](https://github.com/ooi-data-review/2018-data-workshops/blob/master/chemistry/examples/extras1/Working_with_ADCP_Data.ipynb)\n",
        "* And [several others](https://github.com/ooi-data-review/2018-data-workshops/tree/master/chemistry/examples)\n",
        "\n",
        "I'm also working on a number of new examples for the [Ocean Data Labs blog](https://datalab.marine.rutgers.edu/blog/).  Here are the first few...\n",
        "* [Comparison of Air and Seawater Temperatures](https://github.com/ooi-data-lab/blog-notebooks/blob/master/201901/Air%20and%20Sea%20Temps.ipynb)\n",
        "* [Some Basic Statistics of CTD Data](https://github.com/ooi-data-lab/blog-notebooks/blob/master/201901/Statistics.ipynb)\n",
        "* [Temperature Correlations](https://github.com/ooi-data-lab/blog-notebooks/blob/master/201902/Temperature%20Correlations.ipynb)\n"
      ]
    }
  ]
}